{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch\n",
    "from HemaDataset import HemaDataset\n",
    "from HemaModel import HemaModel\n",
    "from DINOv2ForRadiology.dinov2.eval.segmentation.utils import UNetDecoder\n",
    "from DINOv2ForRadiology.dinov2.data.transforms import make_segmentation_train_transforms, make_segmentation_eval_transforms\n",
    "\n",
    "from monai.losses.dice import DiceLoss, DiceCELoss\n",
    "from monai.metrics import DiceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 448\n",
    "root = f\"{os.getcwd() + os.sep}data{os.sep}Dataset011_Cell\"\n",
    "\n",
    "train_image_transform, train_target_transform  = make_segmentation_train_transforms(resize_size=image_size)\n",
    "eval_image_transform, eval_target_transform  = make_segmentation_eval_transforms(resize_size=image_size)\n",
    "\n",
    "train_dataset = HemaDataset(root=root, split=\"train\", seg_entire_cell=True, image_transform=train_image_transform, target_transform=train_target_transform)\n",
    "val_dataset = HemaDataset(root=root, split=\"val\", seg_entire_cell=True, image_transform=eval_image_transform, target_transform=eval_target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 100\n",
    "epoch_length = math.ceil(len(train_dataset) / batch_size)\n",
    "max_iter = epoch_length * epochs \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "encoder = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').cuda()\n",
    "decoder = UNetDecoder(in_channels=encoder.embed_dim, out_channels=3, image_size=448, resize_image=True).cuda()\n",
    "model = HemaModel(encoder=encoder, decoder=decoder)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = torch.nn.DataParallel(model)    \n",
    "\n",
    "optim_param_groups = [\n",
    "    {\"params\": encoder.parameters(), \"lr\": 1e-5},\n",
    "    {\"params\": decoder.parameters(), \"lr\": 1e-3}\n",
    "]\n",
    "\n",
    "loss_fn = DiceCELoss(sigmoid=True)\n",
    "optimizer = torch.optim.SGD(optim_param_groups, momentum=0.9, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for image, mask in train_loader:\n",
    "\n",
    "        image = image.cuda(non_blocking=True)\n",
    "        mask = mask.cuda(non_blocking=True)\n",
    "\n",
    "        output = model(image)\n",
    "\n",
    "        loss = loss_fn(output, mask)\n",
    "\n",
    "        # compute the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "if epoch % 10 == 0:\n",
    "    eval_metric = DiceMetric(include_background=False, reduction=\"none\") # bug with reduction \"mean,\" will do it manually.\n",
    "    print(f\"epoch: {epoch}, loss for last iteration in epoch {loss}, \", end=\"\")\n",
    "    for image, mask in val_loader:\n",
    "        image = image.cuda(non_blocking=True)\n",
    "        mask = mask.cuda(non_blocking=True)\n",
    "\n",
    "        output = model(image)\n",
    "\n",
    "        eval_metric(y_pred=output, y=mask)\n",
    "        \n",
    "    dice = eval_metric.aggregate().mean(axis=1).mean(axis=0) # take average across classes first (channels), then across batch. \n",
    "    print(f\"dice: {dice}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
